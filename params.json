{"name":"S2graph","tagline":"","body":"\r\n\r\n**s2graph**\r\n===================\r\n\r\n**s2graph** is a **GraphDB** that stores big data using **edges** and **vertices**, and also serves REST APIs for querying information on its edges and vertices. It provide fully  **asynchronous, non-blocking API**. This document defines terms and concepts used in s2graph and describes its REST API. \r\n\r\n\r\nTable of content\r\n-------------\r\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\r\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\r\n**Table of Contents**  *generated with [DocToc](http://doctoc.herokuapp.com/)*\r\n\r\n- [Trying It Out](#trying-it-out)\r\n- [The Data Model](#the-data-model)\r\n- [REST API Glossary](#rest-api-glossary)\r\n- [0. Create a Service - `POST /graphs/createService`](#0-create-a-service---post-graphscreateservice)\r\n  - [0.1 service definition](#01-service-definition)\r\n  - [0.2 optional service definition](#02-optional-service-definition)\r\n- [1. Create a Label - `POST /graphs/createLabel`](#1-create-a-label---post-graphscreatelabel)\r\n  - [1.1 label definition](#11-label-definition)\r\n  - [1.2 label example](#12-label-example)\r\n  - [1.3 Consistency level.](#13-consistency-level)\r\n- [2. (Optionally) Add Extra Indexes - `POST /graphs/addIndex`](#2-optionally-add-extra-indexes---post-graphsaddindex)\r\n- [3. Insert and Manipulate Edges](#3-insert-and-manipulate-edges)\r\n  - [Edge Operations](#edge-operations)\r\n    - [1. Insert - `POST /graphs/edges/insert`](#1-insert---post-graphsedgesinsert)\r\n    - [2. delete - `POST /graphs/edges/delete`](#2-delete---post-graphsedgesdelete)\r\n    - [3. update - `POST /graphs/edges/update`](#3-update---post-graphsedgesupdate)\r\n    - [4. increment - `POST /graphs/edges/increment`](#4-increment---post-graphsedgesincrement)\r\n    - [5. insertBulk - `POST /graphs/edges/insertBulk`](#5-insertbulk---post-graphsedgesinsertbulk)\r\n- [4. (Optionally) Insert and Manipulate Vertices](#4-optionally-insert-and-manipulate-vertices)\r\n    - [1. Insert - `POST /graphs/vertices/insert/:serviceName/:columnName`](#1-insert---post-graphsverticesinsertservicenamecolumnname)\r\n    - [2. delete - `POST /graphs/vertices/delete/:serviceName/:columnName`](#2-delete---post-graphsverticesdeleteservicenamecolumnname)\r\n    - [3. deleteAll - `POST /graphs/vertices/delete/:serviceName/:columnName`](#3-deleteall---post-graphsverticesdeleteservicenamecolumnname)\r\n    - [3. update - `POST /graphs/vertices/update/:serviceName/:columnName`](#3-update---post-graphsverticesupdateservicenamecolumnname)\r\n    - [4. increment](#4-increment)\r\n- [5. Query](#5-query)\r\n  - [1. Definition](#1-definition)\r\n  - [2. Query API](#2-query-api)\r\n    - [2.1. Edge Queries](#21-edge-queries)\r\n      - [1. POST /graphs/getEdges](#1-post-graphsgetedges)\r\n      - [2. POST /graphs/getEdges/grouped](#2-post-graphsgetedgesgrouped)\r\n      - [3. POST /graphs/getEdgesExcluded](#3-post-graphsgetedgesexcluded)\r\n      - [4. POST /graphs/getEdgesExcluded/grouped](#4-post-graphsgetedgesexcludedgrouped)\r\n    - [2.2. Vertex Queries](#22-vertex-queries)\r\n      - [1. POST /graphs/getVertices](#1-post-graphsgetvertices)\r\n  - [3. Query Examples](#3-query-examples)\r\n    - [3.1. Edge Queries](#31-edge-queries)\r\n    - [3.2. Vertex Queries](#32-vertex-queries)\r\n- [6. Bulk Loading](#6-bulk-loading)\r\n    - [Edge Format](#edge-format)\r\n    - [Vertex Format](#vertex-format)\r\n  - [Source Data Storage Options](#source-data-storage-options)\r\n    - [1. When the source data is in HDFS.](#1-when-the-source-data-is-in-hdfs)\r\n    - [2. When the source data is in the local file system.](#2-when-the-source-data-is-in-the-local-file-system)\r\n- [7. Benchmark](#7-benchmark)\r\n  - [Test data](#test-data)\r\n    - [1. friend of friend](#1-friend-of-friend)\r\n    - [2. friends](#2-friends)\r\n\r\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\r\n\r\n\r\nGetting Started\r\n-------------\r\n\r\nS2Graph consists of multiple projects.\r\n\r\n1. **S2Core**: core library for common classes to store and retrieve data as edge/vertex. \r\n2. **root project**: Play rest server that provide rest APIs.\r\n3. **spark**: spark related common classes. \r\n4. **loader**: spark jobs that consume events from Kafka to HBase using S2Core library. also contains migration kit from hdfs to s2graph.\r\n5. **asynchbase**: This is fork from https://github.com/OpenTSDB/asynchbase. we add few functionalities on GetRequest. all theses are heavily relies on pull requests which not have been merged on original project yet. \r\n\t6. rpcTimeout\r\n\t7. setFilter\r\n\t8. column pagination\r\n\t9. retryAttempCount\r\n\t10. timestamp filtering\r\n\r\n\r\n----------\r\n\r\n\r\nto build projects \r\n\r\ninstall dependencies on local.\r\n```\r\ncd asynchbase; mvn install \r\n```\r\n\r\ncompile(optional)\r\n```\r\nsbt compile\r\n```\r\n\r\nrun rest server\r\n```\r\nsbt -Dphase={dev/alpha/real/sandbox} run\r\n```\r\n>note that you need to create directory named \"res\" and create phase/conf/application.conf for configuration specific per phase. \r\n>\r\n>ex) mkdir -p res/dev/conf; cp conf/reference.conf dev/conf/application.conf; sbt \"run -Dphase=dev\" will load application.conf under phase/conf/application.conf\r\n\r\n\r\n\r\n\r\n\r\nThe Data Model\r\n--------------\r\n\r\nThere are four important abstractions that define the data model used throughout s2graph: services, columns, labels and properties.\r\n\r\n**Services**, the top level abstraction, are like databases in traditional RDBMS in which all data are contained. A service usually represents one of the company's real services and is named accordingly, e.g. `\"KakaoTalk\"`, `\"KakaoStory\"`.\r\n\r\n**Columns** define the type of vertices and a service can have multiple columns. For example, service `\"KakaoMusic\"` can have columns `\"user_id\"` and `\"track_id\"`. While columns can be compared to tables in traditional RDBMS in a sense, labels are the primary abstraction for representing schemas and columns are usually referenced only using their names.\r\n\r\n**Labels**, represent relations between two columns, therefore representing the type of edges. The two columns can be the same, e.g. for a label representing friendships in an SNS, the two column will both be `\"user_id\"` of the service. There can be labels connecting two columns from two different services; for example, one can create a label that stores all events where KakaoStory posts are shared to KakaoTalk.\r\n\r\n**Properties**, are metadata linked to vertices or edges that can be queried upon later. For vertices representing KakaoTalk users, `estimated_birth_year` is a possible property, and for edges representing similar KakaoMusic songs their `cosine_similarity` can be a property.\r\n\r\nUsing these abstractions, a unique vertex can be identified with its `(service, column, vertex id)`, and a unique edge can be identified with its `(service, label, source vertex id, target vertex id)`. Additional information on edges and vertices are stored within their own properties.\r\n\r\n\r\nREST API Glossary\r\n-----------------\r\n\r\nThe following is a non-exhaustive list of commonly used s2graph APIs and their examples. The full list of the latest REST API can be found in [the routes file](res/conf/routes).\r\n\r\n## 0. Create a Service - `POST /graphs/createService`  ##\r\n\r\n\r\nsee following to see what you can set with this API.\r\n\r\n### 0.1 service definition\r\nTo create a Service, the following fields needs to be specified in the request.\r\n\r\n|field name |  definition | data type |  example | note |\r\n|:------- | --- |:----: | --- | :-----|\r\n| **serviceName** | name of user defined namespace. | string | \"talk_friendship\"| required. |\r\n| cluster | zookeeper quorum address for your cluster.| string | \"abc.com:2181,abd.com:2181\" | optional. <br>default value is \"hbase.zookeeper.quorum\" on your application.conf. if there is no value for \"hbase.zookeeper.quorum\" is defined on application.conf, then default value is \"localhost\" |\r\n| hTableName | physical HBase table name.|string| \"test\"| optional. <br> default is serviceName-#{phase}. <br> phase is either dev/real/alpha/sandbox |\r\n| hTableTTL | global time to keep the data alive. | integer | 86000 | optional. default is infinite.\r\n| preSplitSize | number of pre split for HBase table.| integer|20|optional. <br> default is 0(no pre-split)|\r\n\r\nService is the top level abstraction in s2graph which can be considered like a database in RDBMS. You can create a service using this API:\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/createService -H 'Content-Type: Application/json' -d '\r\n{\"serviceName\": \"s2graph\", \"cluster\": \"address for zookeeper\", \"hTableName\": \"hbase table name\", \"hTableTTL\": 86000, \"preSplitSize\": # of pre split}\r\n'\r\n```\r\n>note that optional value for your service is only advanced users only. stick to default if you don`t know what you are doing.\r\n\r\nYou can also look up all labels corresponding to a service.\r\n\r\n```\r\ncurl -XGET localhost:9000/graphs/getLabels/:serviceName\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## 1. Create a Label - `POST /graphs/createLabel` ##\r\n\r\n\r\n----------\r\n\r\n\r\nA label represents a relation between two columns, and plays a role like a table in RDBMS since labels contain the schema information, i.e. what type of data will be collected and what among them needs to be indexed for efficient retrieval. In most scenario, defining a schema on vertices is pretty straightforward but defining a schema on edges requires a little effort. Think about queries you will need first, and then model user's actions/relations as **edges** to design a label.\r\n\r\n### 1.1 label definition\r\nTo create a Label, the following fields needs to be specified in the request.\r\n\r\n|field name |  definition | data type |  example | note |\r\n|:------- | --- |:----: | --- | :-----|\r\n| **label** | name of this relation; be specific. | string | \"talk_friendship\"| required. |\r\n| srcServiceName | source column's service | string | \"kakaotalk\" | required. |\r\n| srcColumnName | source column's name |string| \"user_id\"|required. |\r\n| srcColumnType | source column's data type | long/integer/string|\"string\"|required.|\r\n| tgtServiceName | target column's service | string | \"kakaotalk\"/\"kakaoagit\" | same as srcServiceName when not specified\r\n| tgtColumnName | target column's name |string|\"item_id\"|required.|\r\n| tgtColumnType | target column's data type | long/integer/string | \"long\" | required. |\r\n| **indexProps** | mapping from indexed properties' names to their default values. <br> indexed properties will be primary index for this label (like `PRIMARY INDEX idx_xxx` (`p1, p2`)`, in RDBMS.<br> **note that _timestamp, _from, _to** is reserved property | json dictionary | {\"timestamp\":0, \"affinity_score\":10, \"play_count\":0}| A default value must be provided for each property. The default value is usually the minimum value permitted for the property. When this filed is empty, the default property named `timestamp` will be automatically added and indexed. The value's type can be one of **long/int/bool/byte** and cannot be **float**. If your property is **float** type, you need to convert them to **long/int** first. |\r\n| props | mapping from non-indexed properties' names to their default values. <br> these properties are indexed and therefore cannot be used efficiently for querying, like non-indexed columns in RDBMS|json dictionary|{\"is_hidden\": false, \"country_iso\": \"kr\", \"country_code\": 82}| non-indexed properties can be added later, like `alter table add column` in RDBMS|\r\n| isDirected | if this label is directed or undirected | true/false | true/false | default true |\r\n| **serviceName** | which service this label is belongs to. | either srcServiceName or tgtServiceName |s2graph |default tgtServiceName\r\n| hTableName | if this label need special usecase(such as batch upload), own hbase table name can be used. | string | s2graph-batch | default use service`s hTableName. <br> note that this is optional. |\r\n| hTableTTL | time to data keep alive. | integer |   86000 | default use service`s hTableTTL. <br> note that this is optional. |\r\n| consistencyLevel | if this is strong, only one edge between same from/to can be made. otherwise(week) multiple edges with same from/to can be exist. | string | strong/week | default week |\r\n\r\n>Note. following property names are reserved for system. user can not create property same with these reserved property names. user can use this properties for indexProps/props/where clause on query.\r\n>>1. **_timestamp** is reserved for system wise timestamp. this can be interpreted as last_modified_at\r\n>>2. **_from** is reserved for label`s start vertex.\r\n>>3. **_to** is reserved for \r\n\r\n### 1.2 label example\r\nThe following is an example that creates a label named `graph_test`, which represents the relation between `account_id` in service named `s2graph` and `account_id` in the same service, with indexed properties `timestamp` and `affinity_score` which both have the zero default value.\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/createLabel -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"label\": \"graph_test\",\r\n    \"srcServiceName\": \"s2graph\",\r\n    \"srcColumnName\": \"account_id\",\r\n    \"srcColumnType\": \"long\",\r\n    \"tgtServiceName\": \"s2graph\",\r\n    \"tgtColumnName\": \"item_id\",\r\n    \"tgtColumnType\": \"long\",\r\n    \"indexProps\": {\r\n        \"time\": 0,\r\n        \"weight\": 0\r\n    },\r\n    \"props\": {\r\n        \"is_hidden\": true,\r\n        \"is_blocked\": true,\r\n        \"error_code\": 500\r\n    }, \r\n    \"serviceName\": \"s2graph\",\r\n    \"consistencyLevel\": \"strong\"\r\n}\r\n'\r\n```\r\n\r\nHere is another example that creates a label named `kakao_group_join` label between column `account_id` of service `kakao` and column `group_id` of service `kakaogroup`. Note that the default indexed property `timestamp` will be created since the `indexedProps` field is empty.\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/createLabel -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"label\": \"kakao_group_join\",\r\n    \"srcServiceName\": \"kakao\",\r\n    \"srcColumnName\": \"account_id\",\r\n    \"srcColumnType\": \"long\",\r\n    \"tgtServiceName\": \"kakaogroup\",\r\n    \"tgtColumnName\": \"group_id\",\r\n    \"tgtColumnType\": \"string\",\r\n    \"indexProps\": {},\r\n    \"serviceName\": \"kakaogroup\",\r\n    \"props\": {}\r\n}\r\n'\r\n```\r\n\r\nThe following query will return the information regarding a label, `graph_test` in this case.\r\n\r\n```\r\ncurl -XGET localhost:9000/graphs/getLabel/graph_test\r\n```\r\n\r\nYou can delete a label using the following API:\r\n\r\n```\r\ncurl -XPUT localhost:9000/graphs/deleteLabel/graph_test\r\n```\r\n\r\nTo add a new non-indexed property, use the following API:\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/addProp/graph_test -H 'Content-Type: Application/json' -d '\r\n{\"name\": \"is_blocked\", \"defaultValue\": false, \"dataType\": \"boolean\", \"usedInIndex\": false}\r\n'\r\n```\r\n\r\n### 1.3 Consistency level.\r\nOne last important constraint on label is **consistency level**.\r\n\r\n>**This define how to store edges on storage level. note that query is completely independent with this.**\r\n\r\nTo explain consistency, s2graph defined edge uniquely with their (from, label, to) triple. s2graph call this triple as unique edge key.\r\n\r\nfollowing example is used to explain differences between strong/week consistency level.\r\n> ```\r\n> 1418950524721\tinsert\te\t1 \t101\tgraph_test\t{\"weight\": 10} = (1, graph_test, 101)\r\n> 1418950524723\tinsert\te\t1\t101\tgraph_test\t{\"weight\": 20} = (1, graph_test, 101)\r\n> ```\r\n\r\ncurrently there are two consistency level \r\n\r\n\r\n**1. strong**\r\n>make sure there is **only one edge stored in storage** between same edge key(**(1, graph_test, 101)** above).\r\n>with strong consistency level, last command overwrite previous command. \r\n\r\n**2. week**\r\n>no consistency check on unique edge key. above example yield **two different edge stored in storage** with different timestamp and weight value.\r\n\r\nfor example, with each configuration, following edges will be stored.\r\n\r\nassumes that only timestamp is used as indexProps and user inserts following.\r\n```\r\nu1 -> (t1, v1)\r\nu1 -> (t2, v2)\r\nu1 -> (t3, v2)\r\nu1 -> (t4, v1)\r\n```\r\n\r\nwith strong consistencyLevel following is what to be stored.\r\n```\r\nu1 -> (t4, v1), (t3, v2)\r\n```\r\nnote that u1 -> (t1, v1), (t2, v2) are not exist.\r\n\r\nwith week consistencyLevel.\r\n```\r\nu1 -> (t4, v1), (t3, v2), (t2, v2), (t1, v1)\r\n```\r\n\r\nReason week consistency is default.\r\n\r\n> most case edges related to user`s activity should use **week** consistencyLevel since there will be **no concurrent update on same edges**. strong consistencyLevel is only for edges expecting many concurrent updates.\r\n\r\n\r\nConsistency level also determine how edges will be stored in storage when command is delivered reversely by their timestamp.\r\n\r\nwith strong consistencyLevel following is guaranteed.\r\n\r\nnatural event on (1, graph_test, 101) unique edge key is following.\r\n```\r\n1418950524721\tinsert\te\t1\t101\tgraph_test\t{\"is_blocked\": false}\r\n1418950524722\tdelete\te\t1\t101\tgraph_test\r\n1418950524723\tinsert\te\t1\t101\tgraph_test\t{\"is_hidden\": false, \"weight\": 10}\r\n1418950524724\tupdate\te\t1\t101\tgraph_test\t{\"time\": 1, \"weight\": -10}\r\n1418950524726\tupdate\te\t1\t101\tgraph_test\t{\"is_blocked\": true}\r\n```\r\n\r\neven if above commands arrive in not in order, strong consistency make sure same eventual state on (1, graph_test, 101).\r\n```\r\n1418950524726\tupdate\te\t1\t101\tgraph_test\t{\"is_blocked\": true}\r\n1418950524723\tinsert\te\t1\t101\tgraph_test\t{\"is_hidden\": false, \"weight\": 10}\r\n1418950524722\tdelete\te\t1\t101\tgraph_test\r\n1418950524721\tinsert\te\t1\t101\tgraph_test\t{\"is_blocked\": false}\r\n1418950524724\tupdate\te\t1\t101\tgraph_test\t{\"time\": 1, \"weight\": -10}\r\n```\r\n\r\nThere are many cases that commands arrive in not in order.\r\n>1. client servers are distributed and each client issue command asynchronously. \r\n>2. client servers are distributed and grouped commands.\r\n>3. by using kafka queue, global ordering or message is not guaranteed.\r\n\r\n\r\nFollowing is what s2graph do to make strong consistency level.\r\n```\r\ncomplexity = O(one read) + O(one delete) + O(2 put)\r\n\r\nfetchedEdge = fetch edge with (1, graph_test, 101) from lookup table.\r\n\r\nif fetchedEdge is not exist:\r\n\tcreate new edge same as current insert operation\r\n\tupdate lookup table as current insert operation\r\nelse:\r\n\tvalid = compare fetchedEdge vs current insert operation.\r\n\tif valid: \r\n\t\tdelete fetchedEdge\r\n\t\tcreate new edge after comparing fetchedEdge and current insert.\r\n\t\tupdate lookup table\r\n```\r\n\r\n\r\n>**Limitation**\r\n>Since we write our data to HBase asynchronously, there is no consistency guarantee on same edge within our flushInterval(1 seconds).\r\n\r\n\r\n## 2. (Optionally) Add Extra Indexes - `POST /graphs/addIndex` ##\r\n\r\n\r\n----------\r\n\r\n\r\nA label can have multiple indexed properties, or (for brevity) indexes. When queried, returned edges' order is determined according to indexes, indexes essentially defines what will be included in the **topK** query.\r\n\r\n> Edge retrieval queries in s2graph by default returns **topK** edges. Clients must issue another query to fetch the next K edges, i.e., **topK ~ 2topK**.\r\n\r\nInternally, s2graph stores edges sorted according to the indexes in order to limit the number of edges to fetch in one query. If no ordering is given, s2graph will use the **timestamp** as an index, thus resulting in the most recent data.\r\n\r\n> It is impossible to fetch millions of edges and sort them on-line to get topK in less than a second. s2graph uses vertex-centric indexes to avoid this.\r\n>\r\n> **using vertex-centric index, having millions of edges is fine as long as the topK value is reasonable (~ 1K)**\r\n> **Note that indexes must be created before putting any data on this label** (just like RDBMS).\r\n\r\nNew indexes can be dynamically added, but it will not be applied to existing data(planned in future versions). **the number of indexes on a label is currently limited to 8.**\r\n\r\nThe following is an example of adding indexes `play_count` and `pay_amount` to a label named `graph_test`.\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/addIndex -H 'Content-Type: Application/json' -d '\r\n{\"label\": \"graph_test\", \"indexProps\": {\"play_count\":0, \"pay_amount\":0}}\r\n'\r\n```\r\n\r\n\r\n##3. Insert and Manipulate Edges ##\r\n\r\n\r\n----------\r\n\r\n\r\nAn **edge** represents a relation between two vertices, with properties according to the schema defined in its label. The following fields need to be specified when inserting an edge, and are returned when queried on edges.\r\n\r\n| field name |  definition | data type |  note | example |\r\n|:------- | --- |:----: | --- | :-----|\r\n| **timestamp** | when this request is issued. | long | required. in **millis** since the epoch. It is important to use millis, since TTL support is in millis.  | 1430116731156 |\r\n| operation |insert/delete/update/increment | string | required only for bulk operation; aliases are insert: i, delete:d, update: u, increment: in, default is insert.| \"i\", \"insert\" |\r\n| from |  Id of start vertex. |  long/string  | required. prefer long if possible. **maximum string bytes length < 249** |1|\r\n| to | Id of end vertex. |  long/string | required. prefer long if possible. **maximum string bytes length < 249** |101|\r\n| label | name the corresponding label  | string | required. |\"graph_test\"|\r\n| direction | direction of this relation, one of **out/in/undirected** | string | required. alias are out: o, in: i, undirected: u| \"out\" |\r\n| props | extra properties of this edge. | json dictionary | required. **all indexed properties should be present, otherwise the default values will be added. Non-indexed properties can also be present** | {\"timestamp\": 1417616431, \"affinity_score\":10, \"is_hidden\": false, \"is_valid\": true}|\r\n\r\n\r\n### Edge Operations ###\r\n\r\n\r\n#### 1. Insert - `POST /graphs/edges/insert` ####\r\n\r\ninsert have different behavior according to label`s consistency level.\r\n\r\n1. strong consistency level(default): **1 READ + (1 DELETE+ 1 PUT, optional)**\r\ninsert is equal to upsert. s2graph check if unique edge key exist, then if there is edge with same unique edge key, run validation then decide apply current request or drop it. \r\n\r\n2. week consistency level: **2 PUT**\r\nno consistency check on unique edge key, insert same edge key multiple times can possibly yield multiple edges.\r\n\r\n\r\nFor consistency reasons, graph databases typically go through the following three steps to insert an edge between a source vertex to a target vertex with some metadata:\r\n\r\n>1. fetch the source vertex to make sure it exists\r\n>2. fetch the target vertex to make sure it exists\r\n>3. insert an edge with the metadata on from -> to\r\n\r\nUnlike other graph databases like **Titan** where server-generated vertex ids must be used, any user-defined vertex ids can be used in s2graph. Therefore s2graph will not fetch vertex data during the insert operation, making it one simple write to the underlying database.\r\n\r\n> **This means that you don't have to create source and target vertices prior to inserting edges, if you don't need any properties on vertices(i.e., you only need vertex id). In this case, s2graph will not fetch vertex information from the underlying db, therefore no read operation is required.**\r\n\r\n\r\nThe following is an example inserting edges:\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/edges/insert -H 'Content-Type: Application/json' -d '\r\n[\r\n  {\"from\":1,\"to\":101,\"label\":\"graph_test\",\"props\":{\"time\":-1, \"weight\":10},\"timestamp\":1417616431},\r\n  {\"from\":1,\"to\":102,\"label\":\"graph_test\",\"props\":{\"time\":0, \"weight\":11},\"timestamp\":1417616431},\r\n  {\"from\":1,\"to\":103,\"label\":\"graph_test\",\"props\":{\"time\":1, \"weight\":12},\"timestamp\":1417616431},\r\n  {\"from\":1,\"to\":104,\"label\":\"graph_test\",\"props\":{\"time\":-2, \"weight\":1},\"timestamp\":1417616431}\r\n]\r\n'\r\n```\r\n\r\n#### 2. delete - `POST /graphs/edges/delete`  ####\r\n\r\nYou can also delete edges.\r\n\r\n> **Note that if the timestamp in a delete request is larger (later) than the actual timestamp of the edge, the delete request will be ignored.**\r\n\r\nThe following is an example deleting edges.\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/edges/delete -H 'Content-Type: Application/json' -d '\r\n[\r\n {\"from\":1,\"to\":102,\"label\":\"graph_test\",\"timestamp\":1417616432},\r\n {\"from\":1,\"to\":103,\"label\":\"graph_test\",\"timestamp\":1417616432}\r\n]\r\n'\r\n```\r\n\r\n#### 3. update - `POST /graphs/edges/update` ####\r\n\r\nAn update request on edges will overwrite properties of the corresponding edge.\r\n\r\n\r\n> This is **not an upsert operation** and a corresponding edge must exist for update operation. Update operations on nonexistent edges will be ignored. \r\n>\r\n> **Also remember that previous data stored in the edge is overwritten.**\r\n\r\nThe following is an example updating properties of an edge, first setting `is_hidden` property to be true and then setting `weight` property to be 100.\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/edges/update -H 'Content-Type: Application/json' -d '\r\n[\r\n {\"from\":1,\"to\":104,\"label\":\"graph_test\",\"timestamp\":1417616433, \"props\": {\"is_hidden\":true}},\r\n {\"from\":1,\"to\":104,\"label\":\"graph_test\",\"timestamp\":1417616434, \"props\": {\"weight\":100}}\r\n]\r\n'\r\n```\r\n\r\n#### 4. increment - `POST /graphs/edges/increment`  ####\r\n\r\nYou can add a certain value to **edges' indexed properties**. Negative numbers can be used to subtract some value from the properties. **Increment operations are only supported for indexed properties.**\r\n\r\n> **you don't have to insert an edge prior to its increment operation. If the edge corresponding to an increment request is not found, a new edge filled with the default property values (provided when defining the label) will be automatically created.**\r\n\r\nThe following is an example incrementing edges' properties.\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/edges/increment -H 'Content-Type: Application/json' -d '\r\n[\r\n  {\"from\":1,\"to\":101,\"label\":\"graph_test\",\"props\":{\"time\":-1, \"weight\":10},\"timestamp\":1417616435},\r\n  {\"from\":1,\"to\":102,\"label\":\"graph_test\",\"props\":{\"time\":0, \"weight\":11},\"timestamp\":1417616435},\r\n  {\"from\":1,\"to\":103,\"label\":\"graph_test\",\"props\":{\"time\":1, \"weight\":12},\"timestamp\":1417616435},\r\n  {\"from\":1,\"to\":104,\"label\":\"graph_test\",\"props\":{\"time\":-2, \"weight\":1},\"timestamp\":1417616435}\r\n]\r\n'\r\n```\r\n\r\n#### 5. insertBulk - `POST /graphs/edges/insertBulk` ####\r\n\r\ninsert edges without **`checking consistency`**. \r\n\r\nThe following is an example inserting edges:\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/edges/insertBulk -H 'Content-Type: Application/json' -d '\r\n[\r\n  {\"from\":1,\"to\":101,\"label\":\"graph_test\",\"props\":{\"time\":-1, \"weight\":10},\"timestamp\":1417616431},\r\n  {\"from\":1,\"to\":101,\"label\":\"graph_test\",\"props\":{\"time\":0, \"weight\":11},\"timestamp\":1417616432}\r\n]\r\n'\r\n```\r\n## 4. (Optionally) Insert and Manipulate Vertices ##\r\n\r\n\r\n\r\nVertices are the two ends that an edge is connecting, and correspond to a column defined for a service. In case you need to store some metadata corresponding to vertices and make queries regarding them, you can insert and manipulate vertices rather than edges.\r\n\r\nUnlike edges and their labels, properties on vertices are not indexed and do not require a predefined schema nor default values. The following fields are used when operating on vertices. \r\n\r\n| field name |  definition | data type |  note | example |\r\n|:------- | --- |:----: | --- | :-----|\r\n| timestamp |  | long | required. in seconds since the epoch | 1417616431 |\r\n| operation | the operation to perform; one of insert, delete, update, increment | string | required only for bulk operations; alias are insert: i, delete:d, update: u, increment: in, default is insert.| \"i\", \"insert\" |\r\n| **serviceName** | corresponding service's name | \"string\" | required. | \"kakaotalk\"/\"kakaogroup\"|\r\n| **columnName** | corresponding column's name |  string  | required. |\"xxx_service_ user_id\"|\r\n| id     | a unique identifier of this vertex |  long/string | required. prefer long if possible.|101|\r\n| **props** | extra properties of this vertex. | json dictionary | required.  | {\"is_active_user\": true, \"age\":10, \"gender\": \"F\", \"country_iso\": \"kr\"}|\r\n\r\n\r\n\r\n----------\r\n\r\n#### 1. Insert - `POST /graphs/vertices/insert/:serviceName/:columnName` ####\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/vertices/insert/s2graph/account_id -H 'Content-Type: Application/json' -d '\r\n[\r\n  {\"id\":1,\"props\":{\"is_active\":true, \"talk_user_id\":10},\"timestamp\":1417616431},\r\n  {\"id\":2,\"props\":{\"is_active\":true, \"talk_user_id\":12},\"timestamp\":1417616431},\r\n  {\"id\":3,\"props\":{\"is_active\":false, \"talk_user_id\":13},\"timestamp\":1417616431},\r\n  {\"id\":4,\"props\":{\"is_active\":true, \"talk_user_id\":14},\"timestamp\":1417616431},\r\n  {\"id\":5,\"props\":{\"is_active\":true, \"talk_user_id\":15},\"timestamp\":1417616431}\r\n]\r\n'\r\n```\r\n\r\n#### 2. delete - `POST /graphs/vertices/delete/:serviceName/:columnName` ####\r\n\r\nThis operation will delete only the vertex data of a specified column and will **not** delete all edges connected to those vertices. \r\n\r\n**Important notes**\r\n>**This means that edges returned by a query can contain deleted vertices. Clients need to check if those vertices are valid.**\r\n\r\n#### 3. deleteAll - `POST /graphs/vertices/delete/:serviceName/:columnName` ####\r\n\r\nThis operation will delete all vertex data of a specified column and also delete all edges that are connected to those vertices. Example:\r\n\r\n```\r\ncurl -XPOST localhost:9000/graphs/vertices/deleteAll/s2graph/account_id -H 'Content-Type: Application/json' -d '\r\n[{\"id\": 1, \"timestamp\": 193829198}]\r\n'\r\n```\r\n\r\nThis is an extremely expensive operation; The following is a pseudocode showing how this operation works:\r\n\r\n```\r\nvertices = vertex list to delete\r\nfor vertex in vertices\r\n\tlabals = fetch all labels that this vertex is included.\r\n\tfor label in labels\r\n\t\tfor index in label.indices\r\n\t\t\tedges = G.read with limit 50K\r\n\t\t\tfor edge in edges\r\n\t\t\t\tedge.delete\r\n```\r\n\r\nThe total complexity is O(L * L.I) reads + O(L * L.I * 50K) writes in the worst case. **If a vertex to delete has more than 50K edges, the delete operation will not be consistent.** \r\n\r\n\r\n\r\n#### 3. update - `POST /graphs/vertices/update/:serviceName/:columnName` ####\r\n\r\nThe update operation on vertices uses the same parameters as in the insert operation.\r\n\r\n#### 4. increment ####\r\n\r\nNot yet implemented; stay tuned.\r\n\r\n\r\n## 5. Query ##\r\n\r\n\r\n\r\n### 1. Definition ###\r\n\r\n\r\n----------\r\n\r\n\r\nOnce you have your graph data uploaded to s2graph, you can traverse your graph using our REST APIs. Queries contain the vertex to start traversing, and list of labels paired with filters and scoring weights used during the traversal. Query requests are structures as follows:\r\n\r\n| field name |  definition | data type |  note | example |\r\n|:------- | --- |:----: | --- | :-----|\r\n| srcVertices | vertices to start traversing. |json array of json dictionary specifying each vertex, with \"serviceName\", \"columnName\", \"id\" fields. | required. | `[{\"serviceName\": \"kakao\", \"columnName\": \"account_id\", \"id\":1}]` |\r\n|**steps**| list of steps for traversing. | json array of steps | explained below| ```[[{\"label\": \"graph_test\", \"direction\": \"out\", \"limit\": 100, \"scoring\":{\"time\": 0, \"weight\": 1}}]] ``` |\r\n|removeCycle| when traverse to next step, don`t traverse already visited vertices| true/false. default is true | already visited is defined by following(label, vertex). <br> so if steps are friend -> friend, then remove second depth friends if they exist in first depth friends | |\r\n\r\n\r\n**step**: Each step define what to traverse in a single hop on the graph. The first step has to be a direct neighbor of the starting vertices, the second step is a direct neighbor of vertices from the first step and so on. A step is specified with a list of **query param**s, hence the `steps` field of a query request becoming an array of arrays of dictionaries.\r\n\r\n**query param**: \r\n\r\n| field name |  definition | data type |  note | example |\r\n|:------- | --- |:----: | --- | :-----|\r\n| label | name of label to traverse.| string | required. must be an existing label. | \"graph_test\" |\r\n| direction | in/out direction to traverse | string | optional, default out | \"out\" |\r\n| limit | how many edges to fetch | int | optional, default 10 | 10 |\r\n| offset | start position on this index | int | optional, default 0 | 50 |\r\n| interval | the range to filter on indexed properties | json dict | optional | `{\"from\": {\"time\": 0, \"weight\": 1}, \"to\": {\"time\": 1, \"weight\": 15}}` |\r\n| duration | time range | json dict | optional| `{\"from\": 1407616431, \"to\": 1417616431}` |\r\n| scoring | a mapping from indexed properties' names to their weights <br> the weighted sum of property values will be the final score. | json dict| optional | `{\"time\": 1, \"weight\": 2}` |\r\n| where | filter condition(like sql`s where clause). <br> logical operation(**and/or**) is supported and each condition can have exact equal(=), sets(in), and range(between x and y). <br> **do not use any quotes for string type** | string | optional | ex) \"((_from = 123 and _to = abcd) or gender = M) and is_hidden = false and weight between 1 and 10 or time in (1, 2, 3)\". <br> note that it only support **long/string/boolean type**|\r\n|outputField|replace edge`s to field with this field in props| string | optional | \"outputField\": \"service_user_id\". this change to field into props['service_user_id'] |\r\n|exclude| decide if vertices that appear on this label and different labels in this step should be filtered out | boolean | optional, default false | true, exclude vertices that appear on this label and other labels in this step will be filtered out.|\r\n|include | decide if vertices that appear on this label and different labels in this step should be remain in result. | boolean | optional, default false | | \r\n| duplicate | policy on how to deal with duplicate edges. <br> duplicate edges means edges with same (from, to, label, direction). | string <br> one of \"first\", \"sum\", \"countSum\", \"raw\" | optional, default \"**first**\" | \"**first**\" means only first occurrence of edge survive. <br> \"**sum**\" means sums up all scores of same edges but only one edge survive. <br>\"**countSum**\" means counts up occurrence of same edges but only one edge survive. <br>\"**raw**\" means same edges will be survived as they are. |\r\n| rpcTimeout | timeout for this request | integer | optional, default 100ms | note: maximum value should be less than 1000ms |\r\n| maxAttempt | how many times client will try to fetch result from HBase | integer | optional, default 1 | note: maximum value should be less than 5|\r\n\r\n\r\n### 2. Query API ###\r\n\r\n#### 2.1. Edge Queries ####\r\n\r\nedge query provide following 4 APIs. s2graph itself would not provide any business logic dependent query. it would rather provide necessary data to help implementing business logic.\r\n\r\n##### 1. POST /graphs/getEdges #####\r\nget all edges. flat hierarchy.\r\n```\r\n{\r\n    \"size\": 2,\r\n    \"results\": [\r\n        {\r\n            \"from\": 1,\r\n            \"to\": 88277115755635400,\r\n            \"label\": \"talk_friend_long_term_agg_by_account_id\",\r\n            \"direction\": \"out\",\r\n            \"_timestamp\": 1425088498,\r\n            \"props\": {\r\n                \"talk_user_id\": 41780,\r\n                \"score\": 8,\r\n                \"service_user_id\": 88277115755635400,\r\n                \"profile_id\": 424,\r\n                \"birth_date\": 517,\r\n                \"birth_year\": 1977,\r\n                \"gender\": \"F\"\r\n            },\r\n            \"score\": 8\r\n        },\r\n        {\r\n            \"from\": 1,\r\n            \"to\": 88300639020224930,\r\n            \"label\": \"talk_friend_long_term_agg_by_account_id\",\r\n            \"direction\": \"out\",\r\n            \"_timestamp\": 1425088493,\r\n            \"props\": {\r\n                \"talk_user_id\": 1545029,\r\n                \"score\": 0,\r\n                \"service_user_id\": 88300639020224930,\r\n                \"profile_id\": 9571562,\r\n                \"birth_date\": 605,\r\n                \"birth_year\": 1979,\r\n                \"gender\": \"F\"\r\n            },\r\n            \"score\": 0\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\n##### 2. POST /graphs/getEdges/grouped #####\r\nget all edges with group by edge`s target vertex.\r\n```\r\n{\r\n    \"size\": 2,\r\n    \"results\": [\r\n        {\r\n            \"name\": \"account_id\",\r\n            \"id\": \"88277115755635393\",\r\n            \"scoreSum\": 8,\r\n            \"aggr\": {\r\n                \"name\": \"account_id\",\r\n                \"ids\": [\r\n                    \"1\"\r\n                ]\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"account_id\",\r\n            \"id\": \"88300639020224928\",\r\n            \"scoreSum\": 0,\r\n            \"aggr\": {\r\n                \"name\": \"account_id\",\r\n                \"ids\": [\r\n                    \"1\"\r\n                ]\r\n            }\r\n        }\r\n    ]\r\n}\r\n```\r\n#####  3. POST /graphs/getEdgesExcluded #####\r\nget all edges excluding all edges from srcVertices to last step.\r\n\r\n#####  4. POST /graphs/getEdgesExcluded/grouped #####\r\nget all edges excluding all edges from srcVertices to last step with group by edge`s target vertex.\r\n\r\n\r\n\r\n#### 2.2. Vertex Queries ####\r\n\r\n##### 1. POST /graphs/getVertices #####\r\nget all vertex data. \r\n\r\n\r\n\r\n\r\n### 3. Query Examples ###\r\n\r\n\r\n\r\n#### 3.1. Edge Queries ####\r\n\r\nExample 1. Selecting the first 100 edges of label `graph_test`, which start from the vertex with `account_id=1`, sorted using the default index of `graph_test`.\r\n\r\n```javascript\r\ncurl -XPOST localhost:9000/graphs/getEdges -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"srcVertices\": [{\"serviceName\": \"s2graph\", \"columnName\": \"account_id\", \"id\":1}],\r\n    \"steps\": [\r\n      [{\"label\": \"graph_test\", \"direction\": \"out\", \"offset\": 0, \"limit\": 100\r\n      }]\r\n    ]\r\n}\r\n'\r\n```\r\n\r\nExample 2. Selecting the 50th ~ 100th edges from the same vertex.\r\n\r\n```javascript\r\ncurl -XPOST localhost:9000/graphs/getEdges -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"srcVertices\": [{\"serviceName\": \"s2graph\", \"columnName\": \"account_id\", \"id\":1}],\r\n    \"steps\": [\r\n      [{\"label\": \"graph_test\", \"direction\": \"in\", \"offset\": 50, \"limit\": 50}]\r\n    ]\r\n}\r\n'\r\n```\r\n\r\nExample 3. Selecting the 50th ~ 100th edges from the same vertex, now with a time range filter.\r\n\r\n```javascript\r\ncurl -XPOST localhost:9000/graphs/getEdges -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"srcVertices\": [{\"serviceName\": \"s2graph\", \"columnName\": \"account_id\", \"id\":1}],\r\n    \"steps\": [\r\n      [{\"label\": \"graph_test\", \"direction\": \"in\", \"offset\": 50, \"limit\": 50, \"duration\": {\"from\": 1416214118, \"to\": 1416214218}]\r\n    ]\r\n}\r\n'\r\n```\r\n\r\nExample 4. Selecting 50th ~ 100th edges from the same vertex, sorted using the indexed properties `time` and `weight`, with the same time range filter, and applying weighted sum using `time: 1.5, weight: 10`\r\n\r\n\r\n```javascript\r\ncurl -XPOST localhost:9000/graphs/getEdges -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"srcVertices\": [{\"serviceName\": \"s2graph\", \"columnName\": \"account_id\", \"id\":1}],\r\n    \"steps\": [\r\n      [{\"label\": \"graph_test\", \"direction\": \"in\", \"offset\": 50, \"limit\": 50, \"duration\": {\"from\": 1416214118, \"to\": 1416214218}, \"scoring\": {\"time\": 1.5, \"weight\": 10}]\r\n    ]\r\n}\r\n'\r\n```\r\n\r\nExample 5. Selecting 100 edges representing `friends`, from the vertex with `account_id=1`, and again selecting their 10 friends, therefore selecting at most 1,000 \"friends of friends\".\r\n\r\n```javascript\r\ncurl -XPOST localhost:9000/graphs/getEdges -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"srcVertices\": [{\"serviceName\": \"s2graph\", \"columnName\": \"account_id\", \"id\":1}],\r\n    \"steps\": [\r\n      [{\"label\": \"friends\", \"direction\": \"out\", \"limit\": 100}],\r\n      [{\"label\": \"friends\", \"direction\": \"out\", \"limit\": 10}]\r\n    ]\r\n}\r\n'\r\n```\r\n\r\nExample 6. Selecting 100 edges representing `friends` and their 10 `listened_music` edges, to get \"music that my friends have listened to\".\r\n\r\n```javascript\r\ncurl -XPOST localhost:9000/graphs/getEdges -H 'Content-Type: Application/json' -d '\r\n{\r\n    \"srcVertices\": [{\"serviceName\": \"s2graph\", \"columnName\": \"account_id\", \"id\":1}],\r\n    \"steps\": [\r\n      [{\"label\": \"talk_friend\", \"direction\": \"out\", \"limit\": 100}],\r\n      [{\"label\": \"play_music\", \"direction\": \"out\", \"limit\": 10}]\r\n    ]\r\n}\r\n'\r\n```\r\n\r\n#### 3.2. Vertex Queries ####\r\n\r\nExample 1. Selecting all vertices from column `account_id` of a service `s2graph`.\r\n\r\n```javascript\r\ncurl -XPOST localhost:9000/graphs/getVertices -H 'Content-Type: Application/json' -d '\r\n[\r\n\t{\"serviceName\": \"s2graph\", \"columnName\": \"account_id\", \"ids\": [1, 2, 3]},\r\n\t{\"serviceName\": \"agit\", \"columnName\": \"user_id\", \"ids\": [1, 2, 3]}\r\n]\r\n'\r\n```\r\n\r\n## 6. Bulk Loading ##\r\n\r\nIn many cases, the first step to start using s2graph is to migrate a large dataset into s2graph. s2graph provides a bulk loading script for importing the initial dataset. \r\n\r\nTo use bulk load, you need running [Spark](https://spark.apache.org/) cluster and **TSV file** with bulk load format.\r\n\r\nNote that if you don't need extra properties on vertices(i.e., you only need vertex id), you only need to publish the edges and not the vertices. Publishing edges will effectively create vertices with empty properties.\r\n\r\n#### Edge Format\r\n\r\n|timestamp | operation | logType |  from | to | label | props |\r\n|:------- | --- |:----: | --- | -----| --- | --- |\r\n|1416236400|insert|edge|56493|26071316|talk_friend_long_term_agg_by_account_id|{\"timestamp\":1416236400,\"score\":0}|\r\n\r\n#### Vertex Format\r\n\r\n|timestamp | operation | logType |  id | serviceName | columnName | props |\r\n|:------- | --- |:----: | --- | -----| --- | --- |\r\n|1416236400|insert|vertex|56493|kakaotalk|account_id|`{\"is_active\":true, \"country_iso\": \"kr\"}`|\r\n\r\n### Build ###\r\nto build bulk loader, you need to build loader project. just run following commend.\r\n\r\n> `sbt \"project loader\" \"clean\" \"assembly\"\r\n\r\nyou will see **s2graph-loader-assembly-0.0.4-SNAPSHOT.jar** under loader/target/scala-2.xx/\r\n\r\n### Source Data Storage Options\r\n\r\nFor bulk loading, source data can be either in HDFS or Kafka queue.\r\n\r\n#### 1. When the source data is in HDFS. ###\r\n \r\n - run subscriber.GraphSubscriber to bulk upload HDFS TSV file into s2graph. \r\n - make sure how many edges are parsed/stored by looking at Spark UI.\r\n\r\n#### 2. When the source data is in Kafka. ####\r\n \r\nassumes that data is bulk loading format and constantly comming into Kafka MQ.\r\n\r\n - run subscriber.GraphSubscriberStreaming to extract and load into s2graph from kafka topic.\r\n - make sure how many edges are parsed/stored by looking at Spark UI.\r\n\r\n#### 3. online migration ####\r\nfollowing is the way we do online migration from RDBMS to s2graph. assumes that client send same events that goes to primary storage(RDBMS) and s2graph.\r\n\r\n - mark label as isAsync true. this will queue all events into kafka queue.\r\n - dump RDBMS and build bulk load file in TSV. \r\n - update TSV file with subscriber.GraphSubscriber.\r\n - mark label as isAsync false. this will stop queuing events into kafka queue and apply changes into s2graph directly. \r\n - since s2graph is Idempotent, it is safe to replay queued message while bulk load process. so just use subscriber.GraphSubscriberStreaming to queued events.\r\n\r\n\r\n## 7. Benchmark ##\r\n\r\n\r\n### Test data\r\n1. kakao talk full graph(8.8 billion edges)\r\n2. sample 10 million user id that have more than 100 friends.\r\n3. number of region server for HBase = 20\r\n\r\n#### 1. friend of friend\r\n**find 50 talk friends then find 20 talk friends**\r\n```\r\n {\r\n    \"srcVertices\": [{\"serviceName\": \"kakaotalk\", \"columnName\": \"talk_user_id\", \"id\":$id}],\r\n    \"steps\": [\r\n      [{\"label\": \"talk_friend\", \"direction\": \"out\", \"limit\": 50}],\r\n      [{\"label\": \"talk_friend\", \"direction\": \"out\", \"limit\": 20}]\r\n    ]\r\n\t}\r\n```\r\n\r\ntotal vuser = 980\r\n\r\n| number of rest server |  tps | mean test time | \r\n|:------- | --- |:----: | --- |\r\n| 10 | 5,981.5 | 151.36 ms | \r\n| 20 | 10,589 | 86.45 ms |\r\n| 30 | 16,295.4 | 56.43 ms | \r\n\r\n\r\n#### 2. friends\r\n**find 100 talk friends**\r\n```\r\n {\r\n    \"srcVertices\": [{\"serviceName\": \"kakaotalk\", \"columnName\": \"talk_user_id\", \"id\":$id}],\r\n    \"steps\": [\r\n      [{\"label\": \"talk_friend\", \"direction\": \"out\", \"limit\": 100}]\r\n    ]\r\n\t}\r\n```\r\n\r\ntotal vuser = 2,072\r\n\r\n| number of rest server |  tps | mean test time |  \r\n|:------- | --- |:----: | --- |\r\n| 20 | 53,713.4 | 37.31 ms | \r\n\r\n\r\n\r\n## new benchmark (asynchbase)\r\n\r\n\r\n#### 1. one step query\r\n```\r\n{\r\n    \"srcVertices\": [\r\n        {\r\n            \"serviceName\": \"kakaotalk\",\r\n            \"columnName\": \"talk_user_id\",\r\n            \"id\": %s    \r\n        }\r\n    ],\r\n    \"steps\": [\r\n      [\r\n        {\r\n          \"label\": \"talk_friend_long_term_agg\", \r\n          \"direction\": \"out\", \r\n          \"offset\": 0, \r\n          \"limit\": %d\r\n        }\r\n      ]\r\n    ]\r\n}\r\n```\r\n| number of rest server |  vuser | offset | first step limit | tps | latency | \r\n|:------- | --- |:----: | --- | --- | --- | --- |\r\n| 1 | 30 | 0 | 10 | 9790TPS | 3ms | \r\n| 1 | 30 | 80 | 10 |  9,958.2TPS | 2.91ms |\r\n| 1 | 30 | 0 | 20 |  7,418.1TPS | 3.92ms | \r\n| 1 | 30 | 0 | 40 | 5,118.5TPS | 5.72ms | \r\n| 1 | 30 | 0 | 60 | 3,966.9TPS | 7.38ms | \r\n| 1 | 30 | 0 | 80 | 3,408.4TPS | 8.58ms | \r\n| 1 | 30 | 0 | 100 | 3,048.1TPS | 9.76ms | \r\n| 2 | 60 | 0 | 100 | 5,869.4TPS | 10.04ms | \r\n| 4 | 120 | 0 | 100 | 11,473.1TPS | 10.27ms | \r\n\r\n#### 2. two step query\r\n```\r\n{\r\n    \"srcVertices\": [\r\n        {\r\n            \"serviceName\": \"kakaotalk\",\r\n            \"columnName\": \"talk_user_id\",\r\n            \"id\": %s    \r\n        }\r\n    ],\r\n    \"steps\": [\r\n      [\r\n        {\r\n          \"label\": \"talk_friend_long_term_agg\", \r\n          \"direction\": \"out\", \r\n          \"offset\": 0, \r\n          \"limit\": %d\r\n        }\r\n      ], \r\n      [\r\n        {\r\n          \"label\": \"talk_friend_long_term_agg\", \r\n          \"direction\": \"out\", \r\n          \"offset\": 0, \r\n          \"limit\": %d\r\n        }\r\n      ]\r\n    ]\r\n}\r\n```\r\n| number of rest server |  vuser | first step limit | second step limit | tps | latency |\r\n|:------- | --- |:----: | --- | --- | --- | --- |  \r\n| 1 | 30 | 10 | 10 | 2,008.2TPS | 14.7ms  | \r\n| 1 | 30 | 10 | 20 | 1,221.3TPS | 24.13ms | \r\n| 1 | 30 | 10 | 40 | 678TPS | 43.92ms |\r\n| 1 | 30 | 10 | 60 | 488.2TPS | 60.72ms | \r\n| 1 | 30 | 10 | 80 | 360.2TPS | 82.55ms | \r\n| 1 | 30 | 10 | 100 | 312.1TPS | 94.7ms | \r\n| 1 | 20 | 10 | 100 | 297TPS | 66.73ms |\r\n| 1 | 10 | 10 | 100 | 302TPS | 32.86ms | \r\n| 1 | 30 | 20 | 10 | 1163.3TPS | 25.5ms | \r\n| 1 | 30 | 20 | 20 | 645.9TPS | 45.79ms | \r\n| 1 | 30 | 40 | 10 | 618.4TPS | 47.96ms | \r\n| 1 | 30 | 60 | 10 | 448.9TPS | 66.16ms | \r\n| 1 | 30 | 80 | 10 | 339.3TPS | 87.82ms | \r\n| 1 | 30 | 100 | 10 | 272.5TPS | 108.65ms | \r\n| 1 | 20 | 100 | 10  | 288.5TPS | 68.34ms | \r\n| 1 | 10 | 100 | 10 | 261.4TPS | 37.49ms | \r\n| 2 | 60 | 100 | 10 | 412.9TPS | 143.83ms | \r\n| 4 | 120 | 100 | 10 | 791.7TPS | 150.06ms | \r\n\r\n#### 3. three step query\r\n```\r\n{\r\n    \"srcVertices\": [\r\n        {\r\n            \"serviceName\": \"kakaotalk\",\r\n            \"columnName\": \"talk_user_id\",\r\n            \"id\": %s    \r\n        }\r\n    ],\r\n    \"steps\": [\r\n      [\r\n        {\r\n          \"label\": \"talk_friend_long_term_agg\", \r\n          \"direction\": \"out\", \r\n          \"offset\": 0, \r\n          \"limit\": %d\r\n        }\r\n      ], \r\n      [\r\n        {\r\n          \"label\": \"talk_friend_long_term_agg\", \r\n          \"direction\": \"out\", \r\n          \"offset\": 0, \r\n          \"limit\": %d\r\n        }\r\n      ],\r\n      [\r\n        {\r\n          \"label\": \"talk_friend_long_term_agg\", \r\n          \"direction\": \"out\", \r\n          \"offset\": 0, \r\n          \"limit\": %d\r\n        }\r\n      ]\r\n    ]\r\n}\r\n```\r\n| number of rest server |  vuser | first step limit | second step limit | third step limit | tps | latency |\r\n|:------- | --- |:----: | --- | --- | --- | --- | --- |  \r\n| 1 | 30 | 10 | 10 | 10 | 250.2TPS | 118.86ms | \r\n| 1 | 30 | 10 | 10 | 20 | 90.4TPS | 329.46ms | \r\n| 1 | 20 | 10 | 10 | 20 | 83.2TPS | 238.42ms | \r\n| 1 | 10 | 10 | 10 | 20 | 82.6TPS | 120.16ms | ","google":"UA-18845229-1","note":"Don't delete this file! It's used internally to help with page regeneration."}